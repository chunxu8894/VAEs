[Custom]
    # General options
    log_level = "info"
    no_progress_bar = False
    no_cuda = False
    seed = 1234

    # Training options
    epochs = 100
    batch_size = 64
    lr = 5e-4
    checkpoint_every = 30
    dataset = 'mnist'
    experiment = 'custom'

    # Model Options
    model = 'Burgess'
    loss = "betaB"
    latent_dim = 10
    rec_dist = "bernoulli"
    # reg_anneal doesn't seem to make much difference but some people say it can help
    reg_anneal = 10000

    # betaH Options
    betaH_B = 4


# ### DATASET COMMON ###
# same number of epochs for comparaisons

[Common_celeba]
    dataset = 'celeba'
    checkpoint_every = 100
    epochs = 200
[Common_mnist]
    dataset = 'mnist'
    checkpoint_every = 100
    epochs = 400

# ### LOSS COMMON ###

[Common_VAE]
    loss = "VAE"
    lr = 5e-4
[Common_betaH]
    loss = "betaH"
    lr = 5e-4

# ### EXPERIMENT SPECIFIC ###
# additional hyperparameter changes besides the common ones

# BETA H

[betaH_celeba]
# beta value as in from https://github.com/1Konny/Beta-VAE
    betaH_B = 10